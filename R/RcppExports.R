# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Build Response Matrix of VAR(p)
#' 
#' This function constructs response matrix of multivariate regression model formulation of VAR(p).
#' 
#' @param y Matrix, multivariate time series data.
#' @param var_lag Integer, VAR lag.
#' @param index Integer, Starting index to extract
#' 
#' @details
#' Let s = n - p.
#' \deqn{Y_j = (y_j, y_{j + 1}, \ldots, y_{j + s - 1})^T}
#' is the s x m matrix.
#' 
#' In case of response matrix, t = p + 1 (i.e. \eqn{Y_0 = Y_{p + 1}}).
#' This function is also used when constructing design matrix.
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' @noRd
build_y0 <- function(y, var_lag, index) {
    .Call(`_bvhar_build_y0`, y, var_lag, index)
}

#' Build Design Matrix of VAR(p)
#' 
#' This function constructs design matrix of multivariate regression model formulation of VAR(p).
#' 
#' @param y Matrix, time series data
#' @param var_lag VAR lag
#' 
#' @details
#' X0 is
#' \deqn{X_0 = [Y_p, \ldots, Y_1, 1]}
#' i.e. (n - p) x (mp + 1) matrix
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' @noRd
build_design <- function(y, var_lag) {
    .Call(`_bvhar_build_design`, y, var_lag)
}

#' Diagonal Matrix
#' 
#' Construct a diagonal matrix.
#' 
#' @param Vector
#' 
#' @noRd
diag_misc <- function(x) {
    .Call(`_bvhar_diag_misc`, x)
}

#' Construct Dummy response for Minnesota Prior
#' 
#' Define dummy Y observations to add for Minnesota moments.
#' 
#' @param p Integer, VAR lag. For VHAR, put 3.
#' @param sigma Vector, standard error of each variable
#' @param lambda Double, tightness of the prior around a random walk or white noise
#' @param daily Vector, prior belief about white noise (Litterman sets 1)
#' @param weekly Vector, this was zero in the original Minnesota design
#' @param monthly Vector, this was zero in the original Minnesota design
#' 
#' @details
#' Bańbura et al. (2010) defines dummy observation and augment to the original data matrix to construct Litterman (1986) prior.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @noRd
build_ydummy <- function(p, sigma, lambda, daily, weekly, monthly) {
    .Call(`_bvhar_build_ydummy`, p, sigma, lambda, daily, weekly, monthly)
}

#' Construct Dummy design matrix for Minnesota Prior
#' 
#' Define dummy X observation to add for Minnesota moments.
#' 
#' @param lag_seq Vector, sequence to build Jp = diag(1, ... p) matrix inside Xp.
#' @param sigma Vector, standard error of each variable
#' @param lambda Double, tightness of the prior around a random walk or white noise
#' @param eps Double, very small number
#' 
#' @details
#' Bańbura et al. (2010) defines dummy observation and augment to the original data matrix to construct Litterman (1986) prior.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @noRd
build_xdummy <- function(lag_seq, lambda, sigma, eps) {
    .Call(`_bvhar_build_xdummy`, lag_seq, lambda, sigma, eps)
}

#' Parameters of Normal Inverted Wishart Prior
#' 
#' Given dummy observations, compute parameters of Normal-IW prior for Minnesota.
#' 
#' @param x_dummy Matrix, dummy observation for X0
#' @param y_dummy Matrix, dummy observation for Y0
#' 
#' @details
#' Minnesota prior give prior to parameters \eqn{B} (VAR matrices) and \eqn{\Sigma_e} (residual covariance) the following distributions
#' 
#' \deqn{B \mid \Sigma_e, Y_0 \sim MN(B_0, \Omega_0, \Sigma_e)}
#' \deqn{\Sigma_e \mid Y_0 \sim IW(S_0, \alpha_0)}
#' (MN: [matrix normal](https://en.wikipedia.org/wiki/Matrix_normal_distribution), IW: [inverse-wishart](https://en.wikipedia.org/wiki/Inverse-Wishart_distribution))
#' 
#' Bańbura et al. (2010) provides the formula how to find each matrix to match Minnesota moments.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @noRd
minnesota_prior <- function(x_dummy, y_dummy) {
    .Call(`_bvhar_minnesota_prior`, x_dummy, y_dummy)
}

#' BVAR(p) Point Estimates based on Minnesota Prior
#' 
#' Point estimates for posterior distribution
#' 
#' @param x Design matrix X0
#' @param y Response matrix Y0
#' @param x_dummy Dummy observations Xp for design matrix X0
#' @param y_dummy Dummy observations Yp for design matrix Y0
#' 
#' @details
#' Augment originally processed data and dummy observation.
#' OLS from this set gives the result.
#' 
#' @references
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' @noRd
estimate_bvar_mn <- function(x, y, x_dummy, y_dummy) {
    .Call(`_bvhar_estimate_bvar_mn`, x, y, x_dummy, y_dummy)
}

#' BVAR(p) Point Estimates based on Nonhierarchical Matrix Normal Prior
#' 
#' Point estimates for Ghosh et al. (2018) nonhierarchical model for BVAR.
#' 
#' @param x Design matrix X0
#' @param y Response matrix Y0
#' @param U Positive definite matrix, covariance matrix corresponding to the column of the model parameter B
#' 
#' @details
#' In Ghosh et al. (2018), there are many models for BVAR such as hierarchical or non-hierarchical.
#' Among these, this function chooses the most simple non-hierarchical matrix normal prior in Section 3.1.
#' 
#' @references
#' Ghosh, S., Khare, K., & Michailidis, G. (2018). *High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models*. Journal of the American Statistical Association, 114(526). [https://doi:10.1080/01621459.2018.1437043](https://doi:10.1080/01621459.2018.1437043)
#' 
#' @noRd
estimate_mn_flat <- function(x, y, U) {
    .Call(`_bvhar_estimate_mn_flat`, x, y, U)
}

#' Building Spike-and-slab SD Diagonal Matrix
#' 
#' In MCMC process of SSVS, this function computes diagonal matrix \eqn{D} or \eqn{D_j} defined by spike-and-slab sd.
#' 
#' @param spike_sd Standard deviance for Spike normal distribution
#' @param slab_sd Standard deviance for Slab normal distribution
#' @param mixture_dummy Indicator vector (0-1) corresponding to each element
#' @noRd
build_ssvs_sd <- function(spike_sd, slab_sd, mixture_dummy) {
    .Call(`_bvhar_build_ssvs_sd`, spike_sd, slab_sd, mixture_dummy)
}

#' Generating the Diagonal Component of Cholesky Factor in SSVS Gibbs Sampler
#' 
#' In MCMC process of SSVS, this function generates the diagonal component \eqn{\Psi} from variance matrix
#' 
#' @param sse_mat The result of \eqn{Z_0^T Z_0 = (Y_0 - X_0 \hat{A})^T (Y_0 - X_0 \hat{A})}
#' @param inv_DRD Inverse of matrix product between \eqn{D_j} and correlation matrix \eqn{R_j}
#' @param shape Gamma shape parameters for precision matrix
#' @param rate Gamma rate parameters for precision matrix
#' @param num_design The number of sample used, \eqn{n = T - p}
#' @noRd
ssvs_chol_diag <- function(sse_mat, inv_DRD, shape, rate, num_design) {
    .Call(`_bvhar_ssvs_chol_diag`, sse_mat, inv_DRD, shape, rate, num_design)
}

#' Generating the Off-Diagonal Component of Cholesky Factor in SSVS Gibbs Sampler
#' 
#' In MCMC process of SSVS, this function generates the off-diagonal component \eqn{\Psi} of variance matrix
#' 
#' @param sse_mat The result of \eqn{Z_0^T Z_0 = (Y_0 - X_0 \hat{A})^T (Y_0 - X_0 \hat{A})}
#' @param chol_diag Diagonal element of the cholesky factor
#' @param inv_DRD Inverse of matrix product between \eqn{D_j} and correlation matrix \eqn{R_j}
#' @noRd
ssvs_chol_off <- function(sse_mat, chol_diag, inv_DRD) {
    .Call(`_bvhar_ssvs_chol_off`, sse_mat, chol_diag, inv_DRD)
}

#' Filling Cholesky Factor Upper Triangular Matrix
#' 
#' This function builds a cholesky factor matrix \eqn{\Psi} (upper triangular) using diagonal component vector and off-diagonal component vector.
#' 
#' @param diag_vec Diagonal components
#' @param off_diagvec Off-diagonal components
#' @noRd
build_chol <- function(diag_vec, off_diagvec) {
    .Call(`_bvhar_build_chol`, diag_vec, off_diagvec)
}

#' Generating Dummy Vector for Parameters in SSVS Gibbs Sampler
#' 
#' In MCMC process of SSVS, this function generates latent \eqn{\gamma_j} or \eqn{\omega_{ij}} conditional posterior.
#' 
#' @param param_obs Realized parameters vector
#' @param spike_sd Standard deviance for Spike normal distribution
#' @param slab_sd Standard deviance for Slab normal distribution
#' @param slab_weight Proportion of nonzero coefficients
#' @noRd
ssvs_chol_dummy <- function(chol_upper, spike_sd, slab_sd, slab_weight) {
    .Call(`_bvhar_ssvs_chol_dummy`, chol_upper, spike_sd, slab_sd, slab_weight)
}

#' Generating Coefficient Vector in SSVS Gibbs Sampler
#' 
#' In MCMC process of SSVS, this function generates \eqn{\alpha_j} conditional posterior.
#' 
#' @param prior_mean The prior mean vector of the VAR coefficient vector
#' @param prior_prec The prior precision matrix of the VAR coefficient vector
#' @param XtX The result of design matrix arithmetic \eqn{X_0^T X_0}
#' @param coef_ols OLS (MLE) estimator of the VAR coefficient
#' @param chol_factor Cholesky factor of variance matrix
#' @noRd
ssvs_coef <- function(prior_mean, prior_prec, XtX, coef_ols, chol_factor) {
    .Call(`_bvhar_ssvs_coef`, prior_mean, prior_prec, XtX, coef_ols, chol_factor)
}

#' Generating Dummy Vector for Parameters in SSVS Gibbs Sampler
#' 
#' In MCMC process of SSVS, this function generates latent \eqn{\gamma_j} or \eqn{\omega_{ij}} conditional posterior.
#' 
#' @param param_obs Realized parameters vector
#' @param spike_sd Standard deviance for Spike normal distribution
#' @param slab_sd Standard deviance for Slab normal distribution
#' @param slab_weight Proportion of nonzero coefficients
#' @noRd
ssvs_coef_dummy <- function(coef, spike_sd, slab_sd, slab_weight) {
    .Call(`_bvhar_ssvs_coef_dummy`, coef, spike_sd, slab_sd, slab_weight)
}

#' BVAR(p) SSVS by Gibbs Sampler
#' 
#' This function conducts Gibbs sampling for BVAR SSVS.
#' 
#' @param num_iter Number of iteration for MCMC
#' @param num_burn Number of burn-in for MCMC
#' @param x Design matrix X0
#' @param y Response matrix Y0
#' @param init_coef Initial k x m coefficient matrix.
#' @param init_chol_diag Inital diagonal cholesky factor
#' @param init_chol_upper Inital upper cholesky factor
#' @param init_coef_dummy Initial indicator vector (0-1) corresponding to each coefficient vector
#' @param init_chol_dummy Initial indicator vector (0-1) corresponding to each upper cholesky factor vector
#' @param coef_slab_weight Bernoulli parameter for coefficients vector
#' @param coef_spike Standard deviance for Spike normal distribution
#' @param coef_slab Standard deviance for Slab normal distribution
#' @param coef_slab_weight Bernoulli parameter for coefficients sparsity proportion
#' @param shape Gamma shape parameters for precision matrix
#' @param rate Gamma rate parameters for precision matrix
#' @param chol_spike Standard deviance for cholesky factor Spike normal distribution
#' @param chol_slab Standard deviance for cholesky factor Slab normal distribution
#' @param chol_slab_weight Bernoulli parameter for cholesky factor sparsity proportion
#' @param intercept_var Hyperparameter for constant term
#' @param chain The number of MCMC chains.
#' @noRd
estimate_bvar_ssvs <- function(num_iter, num_burn, x, y, init_coef, init_chol_diag, init_chol_upper, init_coef_dummy, init_chol_dummy, coef_spike, coef_slab, coef_slab_weight, shape, rate, chol_spike, chol_slab, chol_slab_weight, intercept_var, chain) {
    .Call(`_bvhar_estimate_bvar_ssvs`, num_iter, num_burn, x, y, init_coef, init_chol_diag, init_chol_upper, init_coef_dummy, init_chol_dummy, coef_spike, coef_slab, coef_slab_weight, shape, rate, chol_spike, chol_slab, chol_slab_weight, intercept_var, chain)
}

#' Compute VAR(p) Coefficient Matrices and Fitted Values
#' 
#' This function fits VAR(p) given response and design matrices of multivariate time series.
#' 
#' @param x Design matrix X0
#' @param y Response matrix Y0
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' Y0 = X0 A + Z
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
estimate_var <- function(x, y) {
    .Call(`_bvhar_estimate_var`, x, y)
}

#' Covariance Estimate for Residual Covariance Matrix
#' 
#' Compute ubiased estimator for residual covariance.
#' 
#' @param z Matrix, residual
#' @param num_design Integer, Number of sample used (s = n - p)
#' @param dim_design Ingeger, Number of parameter for each dimension (k = mp + 1)
#' @details
#' See pp75 Lütkepohl (2007).
#' 
#' * s = n - p: sample used (`num_design`)
#' * k = mp + 1 (m: dimension, p: VAR lag): number of parameter for each dimension (`dim_design`)
#' 
#' Then an unbiased estimator for \eqn{\Sigma_e} is
#' 
#' \deqn{\hat{\Sigma}_e = \frac{1}{s - k} (Y_0 - \hat{A} X_0)^T (Y_0 - \hat{A} X_0)}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
compute_cov <- function(z, num_design, dim_design) {
    .Call(`_bvhar_compute_cov`, z, num_design, dim_design)
}

#' Statistic for VAR
#' 
#' Compute partial t-statistics for inference in VAR model.
#' 
#' @param object `varlse` object
#' @details
#' Partial t-statistic for H0: aij = 0
#' 
#' * For each variable (e.g. 1st variable)
#' * Standard error =  (1st) diagonal element of \eqn{\Sigma_e} estimator x diagonal elements of \eqn{(X_0^T X_0)^(-1)}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
infer_var <- function(object) {
    .Call(`_bvhar_infer_var`, object)
}

#' @noRd
VARcoeftoVMA <- function(var_coef, var_lag, lag_max) {
    .Call(`_bvhar_VARcoeftoVMA`, var_coef, var_lag, lag_max)
}

#' Convert VAR to VMA(infinite)
#' 
#' Convert VAR process to infinite vector MA process
#' 
#' @param object `varlse` object
#' @param lag_max Maximum lag for VMA
#' @details
#' Let VAR(p) be stable.
#' \deqn{Y_t = c + \sum_{j = 0} W_j Z_{t - j}}
#' For VAR coefficient \eqn{B_1, B_2, \ldots, B_p},
#' \deqn{I = (W_0 + W_1 L + W_2 L^2 + \cdots + ) (I - B_1 L - B_2 L^2 - \cdots - B_p L^p)}
#' Recursively,
#' \deqn{W_0 = I}
#' \deqn{W_1 = W_0 B_1 (W_1^T = B_1^T W_0^T)}
#' \deqn{W_2 = W_1 B_1 + W_0 B_2 (W_2^T = B_1^T W_1^T + B_2^T W_0^T)}
#' \deqn{W_j = \sum_{j = 1}^k W_{k - j} B_j (W_j^T = \sum_{j = 1}^k B_j^T W_{k - j}^T)}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
VARtoVMA <- function(object, lag_max) {
    .Call(`_bvhar_VARtoVMA`, object, lag_max)
}

#' Compute Forecast MSE Matrices
#' 
#' Compute the forecast MSE matrices using VMA coefficients
#' 
#' @param object `varlse` object
#' @param step Integer, Step to forecast
#' @details
#' See pp38 of Lütkepohl (2007).
#' Let \eqn{\Sigma} be the covariance matrix of VAR and let \eqn{W_j} be the VMA coefficients.
#' Recursively,
#' \deqn{\Sigma_y(1) = \Sigma}
#' \deqn{\Sigma_y(2) = \Sigma + W_1 \Sigma W_1^T}
#' \deqn{\Sigma_y(3) = \Sigma_y(2) + W_2 \Sigma W_2^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
compute_covmse <- function(object, step) {
    .Call(`_bvhar_compute_covmse`, object, step)
}

#' Convert VAR to Orthogonalized VMA(infinite)
#' 
#' Convert VAR process to infinite orthogonalized vector MA process
#' 
#' @param var_coef VAR coefficient matrix
#' @param var_covmat VAR covariance matrix
#' @param var_lag VAR order
#' @param lag_max Maximum lag for VMA
#' @noRd
VARcoeftoVMA_ortho <- function(var_coef, var_covmat, var_lag, lag_max) {
    .Call(`_bvhar_VARcoeftoVMA_ortho`, var_coef, var_covmat, var_lag, lag_max)
}

#' Building a Linear Transformation Matrix for Vector HAR
#' 
#' This function produces a linear transformation matrix for VHAR for given dimension.
#' 
#' @param dim Integer, dimension
#' @param week Integer, order for weekly term
#' @param month Integer, order for monthly term
#' @details
#' VHAR is linearly restricted VAR(month = 22) in \eqn{Y_0 = X_0 A + Z}.
#' \deqn{Y_0 = X_1 \Phi + Z = (X_0 C_{HAR}^T) \Phi + Z}
#' This function computes above \eqn{C_{HAR}}.
#' 
#' Default VHAR model sets `week` and `month` as `5` and `22`.
#' This function can change these numbers to get linear transformation matrix.
#' 
#' @noRd
scale_har <- function(dim, week, month) {
    .Call(`_bvhar_scale_har`, dim, week, month)
}

#' Compute Vector HAR Coefficient Matrices and Fitted Values
#' 
#' This function fits VHAR given response and design matrices of multivariate time series.
#' 
#' @param x Design matrix X0
#' @param y Response matrix Y0
#' @param week Integer, order for weekly term
#' @param month Integer, order for monthly term
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' \deqn{Y_0 = X_1 \Phi + Z}
#' 
#' @references
#' Baek, C. and Park, M. (2021). *Sparse vector heterogeneous autoregressive modeling for realized volatility*. J. Korean Stat. Soc. 50, 495–510. doi:[10.1007/s42952-020-00090-5](https://doi.org/10.1007/s42952-020-00090-5)
#' 
#' Corsi, F. (2008). *A Simple Approximate Long-Memory Model of Realized Volatility*. Journal of Financial Econometrics, 7(2), 174–196. doi:[10.1093/jjfinec/nbp001](https://doi.org/10.1093/jjfinec/nbp001)
#' @importFrom Rcpp sourceCpp
#' @noRd
estimate_har <- function(x, y, week, month) {
    .Call(`_bvhar_estimate_har`, x, y, week, month)
}

#' Compute Vector HAR Coefficient Matrices and Fitted Values without Constant Term
#' 
#' This function fits VHAR given response and design matrices of multivariate time series, when the model has no constant term.
#' 
#' @param x Design matrix X0 (delete its last column)
#' @param y Response matrix Y0
#' @param week Integer, order for weekly term
#' @param month Integer, order for monthly term
#' @details
#' Given Y0 and Y0, the function estimate least squares
#' \deqn{Y_0 = X_1 \Phi + Z}
#' 
#' @references
#' Baek, C. and Park, M. (2021). *Sparse vector heterogeneous autoregressive modeling for realized volatility*. J. Korean Stat. Soc. 50, 495–510. doi:[10.1007/s42952-020-00090-5](https://doi.org/10.1007/s42952-020-00090-5)
#' 
#' Corsi, F. (2008). *A Simple Approximate Long-Memory Model of Realized Volatility*. Journal of Financial Econometrics, 7(2), 174–196. doi:[10.1093/jjfinec/nbp001](https://doi.org/10.1093/jjfinec/nbp001)
#' @noRd
estimate_har_none <- function(x, y, week, month) {
    .Call(`_bvhar_estimate_har_none`, x, y, week, month)
}

#' Statistic for VHAR
#' 
#' Compute partial t-statistics for inference in VHAR model.
#' 
#' @param object `vharlse` object
#' @details
#' Partial t-statistic for H0: \eqn{\phi_{ij} = 0}
#' 
#' * For each variable (e.g. 1st variable)
#' * Standard error =  (1st) diagonal element of \eqn{\Sigma_e} estimator x diagonal elements of \eqn{(X_1^T X_1)^(-1)}
#' @noRd
infer_vhar <- function(object) {
    .Call(`_bvhar_infer_vhar`, object)
}

#' @noRd
VHARcoeftoVMA <- function(vhar_coef, HARtrans_mat, lag_max, month) {
    .Call(`_bvhar_VHARcoeftoVMA`, vhar_coef, HARtrans_mat, lag_max, month)
}

#' Convert VHAR to VMA(infinite)
#' 
#' Convert VHAR process to infinite vector MA process
#' 
#' @param object `vharlse` object
#' @param lag_max Maximum lag for VMA
#' @details
#' Let VAR(p) be stable
#' and let VAR(p) be
#' \eqn{Y_0 = X_0 B + Z}
#' 
#' VHAR is VAR(22) with
#' \deqn{Y_0 = X_1 B + Z = ((X_0 \tilde{T}^T)) \Phi + Z}
#' 
#' Observe that
#' \deqn{B = \tilde{T}^T \Phi}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
VHARtoVMA <- function(object, lag_max) {
    .Call(`_bvhar_VHARtoVMA`, object, lag_max)
}

#' Compute Forecast MSE Matrices for VHAR
#' 
#' Compute the forecast MSE matrices using VMA coefficients
#' 
#' @param object \code{varlse} object by \code{\link{var_lm}}
#' @param step Integer, Step to forecast
#' @details
#' See pp38 of Lütkepohl (2007).
#' Let \eqn{\Sigma} be the covariance matrix of VHAR and let \eqn{W_j} be the VMA coefficients.
#' Recursively,
#' \deqn{\Sigma_y(1) = \Sigma}
#' \deqn{\Sigma_y(2) = \Sigma + W_1 \Sigma W_1^T}
#' \deqn{\Sigma_y(3) = \Sigma_y(2) + W_2 \Sigma W_2^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
compute_covmse_har <- function(object, step) {
    .Call(`_bvhar_compute_covmse_har`, object, step)
}

#' Orthogonal Impulse Response Functions of VHAR
#' 
#' Compute orthogonal impulse responses of VHAR
#' 
#' @param vhar_coef VHAR coefficient
#' @param vhar_covmat VHAR covariance matrix
#' @param HARtrans_mat HAR linear transformation matrix
#' @param lag_max Maximum lag for VMA
#' @param month Order for monthly term
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
VHARcoeftoVMA_ortho <- function(vhar_coef, vhar_covmat, HARtrans_mat, lag_max, month) {
    .Call(`_bvhar_VHARcoeftoVMA_ortho`, vhar_coef, vhar_covmat, HARtrans_mat, lag_max, month)
}

#' Forecasting BVAR(p)
#' 
#' @param object `bvarmn` or `bvarflat` object
#' @param step Integer, Step to forecast
#' @param num_sim Integer, number to simulate parameters from posterior distribution
#' @details
#' n-step ahead forecasting using BVAR(p) recursively.
#' 
#' For given number of simulation (`num_sim`),
#' 
#' 1. Generate \eqn{(A^{(b)}, \Sigma_e^{(b)}) \sim MIW} (posterior)
#' 2. Recursively, \eqn{j = 1, \ldots, h} (`step`)
#'     - Point forecast: Use \eqn{\hat{A}}
#'     - Predictive distribution: Again generate \eqn{\tilde{Y}_{n + j}^{(b)} \sim A^{(b)}, \Sigma_e^{(b)} \sim MN}
#'     - tilde notation indicates simulated ones
#' 
#' @references
#' Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' 
#' Litterman, R. B. (1986). *Forecasting with Bayesian Vector Autoregressions: Five Years of Experience*. Journal of Business & Economic Statistics, 4(1), 25. [https://doi:10.2307/1391384](https://doi:10.2307/1391384)
#' 
#' Bańbura, M., Giannone, D., & Reichlin, L. (2010). *Large Bayesian vector auto regressions*. Journal of Applied Econometrics, 25(1). [https://doi:10.1002/jae.1137](https://doi:10.1002/jae.1137)
#' 
#' Ghosh, S., Khare, K., & Michailidis, G. (2018). *High-Dimensional Posterior Consistency in Bayesian Vector Autoregressive Models*. Journal of the American Statistical Association, 114(526). [https://doi:10.1080/01621459.2018.1437043](https://doi:10.1080/01621459.2018.1437043)
#' 
#' Karlsson, S. (2013). *Chapter 15 Forecasting with Bayesian Vector Autoregression*. Handbook of Economic Forecasting, 2, 791–897. doi:[10.1016/b978-0-444-62731-5.00015-4](https://doi.org/10.1016/B978-0-444-62731-5.00015-4)
#' 
#' @noRd
forecast_bvar <- function(object, step, num_sim) {
    .Call(`_bvhar_forecast_bvar`, object, step, num_sim)
}

#' Forecasting Bayesian VHAR
#' 
#' @param object `bvharmn` object
#' @param step Integer, Step to forecast
#' @param num_sim Integer, number to simulate parameters from posterior distribution
#' @details
#' n-step ahead forecasting using VHAR recursively.
#' 
#' For given number of simulation (`num_sim`),
#' 
#' 1. Generate \eqn{(\Phi^{(b)}, \Sigma_e^{(b)}) \sim MIW} (posterior)
#' 2. Recursively, \eqn{j = 1, \ldots, h} (`step`)
#'     - Point forecast: Use \eqn{\hat\Phi}
#'     - Predictive distribution: Again generate \eqn{\tilde{Y}_{n + j}^{(b)} \sim \Phi^{(b)}, \Sigma_e^{(b)} \sim MN}
#'     - tilde notation indicates simulated ones
#' 
#' @references Kim, Y. G., and Baek, C. (n.d.). *Bayesian vector heterogeneous autoregressive modeling*. submitted.
#' @noRd
forecast_bvharmn <- function(object, step, num_sim) {
    .Call(`_bvhar_forecast_bvharmn`, object, step, num_sim)
}

#' Out-of-Sample Forecasting of VAR based on Expanding Window
#' 
#' This function conducts an expanding window forecasting of VAR.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag VAR order
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
expand_var <- function(y, lag, include_mean, step, y_test) {
    .Call(`_bvhar_expand_var`, y, lag, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of VHAR based on Expanding Window
#' 
#' This function conducts an expanding window forecasting of VHAR.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param har `r lifecycle::badge("experimental")` Numeric vector for weekly and monthly order.
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
expand_vhar <- function(y, har, include_mean, step, y_test) {
    .Call(`_bvhar_expand_vhar`, y, har, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVAR based on Expanding Window
#' 
#' This function conducts an expanding window forecasting of BVAR with Minnesota prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag BVAR order
#' @param bayes_spec List, BVAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
expand_bvar <- function(y, lag, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_expand_bvar`, y, lag, bayes_spec, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVAR based on Expanding Window
#' 
#' This function conducts an expanding window forecasting of BVAR with Flat prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag BVAR order
#' @param bayes_spec List, BVAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
expand_bvarflat <- function(y, lag, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_expand_bvarflat`, y, lag, bayes_spec, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVHAR based on Expanding Window
#' 
#' This function conducts an expanding window forecasting of BVHAR with Minnesota prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param har `r lifecycle::badge("experimental")` Numeric vector for weekly and monthly order.
#' @param bayes_spec List, BVHAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
expand_bvhar <- function(y, har, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_expand_bvhar`, y, har, bayes_spec, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of VAR based on Rolling Window
#' 
#' This function conducts an rolling window forecasting of VAR.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag VAR order
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
roll_var <- function(y, lag, include_mean, step, y_test) {
    .Call(`_bvhar_roll_var`, y, lag, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of VHAR based on Rolling Window
#' 
#' This function conducts an rolling window forecasting of VHAR.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param har `r lifecycle::badge("experimental")` Numeric vector for weekly and monthly order.
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
roll_vhar <- function(y, har, include_mean, step, y_test) {
    .Call(`_bvhar_roll_vhar`, y, har, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVAR based on Rolling Window
#' 
#' This function conducts an rolling window forecasting of BVAR with Minnesota prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag BVAR order
#' @param bayes_spec List, BVAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
roll_bvar <- function(y, lag, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_roll_bvar`, y, lag, bayes_spec, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVAR based on Rolling Window
#' 
#' This function conducts an rolling window forecasting of BVAR with Flat prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag BVAR order
#' @param bayes_spec List, BVAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
roll_bvarflat <- function(y, lag, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_roll_bvarflat`, y, lag, bayes_spec, include_mean, step, y_test)
}

#' Out-of-Sample Forecasting of BVHAR based on Rolling Window
#' 
#' This function conducts an rolling window forecasting of BVHAR with Minnesota prior.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param har `r lifecycle::badge("experimental")` Numeric vector for weekly and monthly order.
#' @param bayes_spec List, BVHAR specification
#' @param include_mean Add constant term
#' @param step Integer, Step to forecast
#' @param y_test Evaluation time series data period after `y`
#' 
#' @noRd
roll_bvhar <- function(y, har, bayes_spec, include_mean, step, y_test) {
    .Call(`_bvhar_roll_bvhar`, y, har, bayes_spec, include_mean, step, y_test)
}

#' Forecasting Vector Autoregression
#' 
#' @param object `varlse` object
#' @param step Integer, Step to forecast
#' @details
#' n-step ahead forecasting using VAR(p) recursively, based on pp35 of Lütkepohl (2007).
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. [https://doi.org/10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
forecast_var <- function(object, step) {
    .Call(`_bvhar_forecast_var`, object, step)
}

#' Forecasting Vector HAR
#' 
#' @param object `vharlse` object
#' @param step Integer, Step to forecast
#' @details
#' n-step ahead forecasting using VHAR recursively.
#' 
#' @noRd
forecast_vhar <- function(object, step) {
    .Call(`_bvhar_forecast_vhar`, object, step)
}

#' Generate Multivariate Normal Random Vector
#' 
#' This function samples n x muti-dimensional normal random matrix.
#' 
#' @param num_sim Number to generate process
#' @param mu Mean vector
#' @param sig Variance matrix
#' @details
#' Consider \eqn{x_1, \ldots, x_n \sim N_m (\mu, \Sigma)}.
#' 
#' 1. Lower triangular Cholesky decomposition: \eqn{\Sigma = L L^T}
#' 2. Standard normal generation: \eqn{Z_{i1}, Z_{in} \stackrel{iid}{\sim} N(0, 1)}
#' 3. \eqn{Z_i = (Z_{i1}, \ldots, Z_{in})^T}
#' 4. \eqn{X_i = L Z_i + \mu}
#' 
#' This function does not care of \eqn{\mu}.
#' 
#' @export
sim_mgaussian <- function(num_sim, mu, sig) {
    .Call(`_bvhar_sim_mgaussian`, num_sim, mu, sig)
}

#' Generate Multivariate Normal Random Vector using Cholesky Decomposition
#' 
#' This function samples n x muti-dimensional normal random matrix with using Cholesky decomposition.
#' 
#' @param num_sim Number to generate process
#' @param mu Mean vector
#' @param sig Variance matrix
#' @details
#' This function computes \eqn{\Sigma^{1/2}} by choleksy decomposition.
#' 
#' @noRd
sim_mgaussian_chol <- function(num_sim, mu, sig) {
    .Call(`_bvhar_sim_mgaussian_chol`, num_sim, mu, sig)
}

#' Generate Matrix Normal Random Matrix
#' 
#' This function samples one matrix gaussian matrix.
#' 
#' @param mat_mean Mean matrix
#' @param mat_scale_u First scale matrix
#' @param mat_scale_v Second scale matrix
#' @details
#' Consider s x m matrix \eqn{Y_1, \ldots, Y_n \sim MN(M, U, V)} where M is s x m, U is s x s, and V is m x m.
#' 
#' 1. Lower triangular Cholesky decomposition: \eqn{U = P P^T} and \eqn{V = L L^T}
#' 2. Standard normal generation: s x m matrix \eqn{Z_i = [z_{ij} \sim N(0, 1)]} in row-wise direction.
#' 3. \eqn{Y_i = M + P Z_i L^T}
#' 
#' This function only generates one matrix, i.e. \eqn{Y_1}.
#' 
#' @export
sim_matgaussian <- function(mat_mean, mat_scale_u, mat_scale_v) {
    .Call(`_bvhar_sim_matgaussian`, mat_mean, mat_scale_u, mat_scale_v)
}

#' Generate Lower Triangular Matrix of IW
#' 
#' This function generates \eqn{A = L (Q^{-1})^T}.
#' 
#' @param mat_scale Scale matrix of IW
#' @param shape Shape of IW
#' @details
#' This function is the internal function for IW sampling and MNIW sampling functions.
#' 
#' @noRd
sim_iw_tri <- function(mat_scale, shape) {
    .Call(`_bvhar_sim_iw_tri`, mat_scale, shape)
}

#' Generate Inverse-Wishart Random Matrix
#' 
#' This function samples one matrix IW matrix.
#' 
#' @param mat_scale Scale matrix
#' @param shape Shape
#' @details
#' Consider \eqn{\Sigma \sim IW(\Psi, \nu)}.
#' 
#' 1. Upper triangular Bartlett decomposition: m x m matrix \eqn{Q = [q_{ij}]} upper triangular with
#'     1. \eqn{q_{ii}^2 \chi_{\nu - i + 1}^2}
#'     2. \eqn{q_{ij} \sim N(0, 1)} with i < j (upper triangular)
#' 2. Lower triangular Cholesky decomposition: \eqn{\Psi = L L^T}
#' 3. \eqn{A = L (Q^{-1})^T}
#' 4. \eqn{\Sigma = A A^T \sim IW(\Psi, \nu)}
#' 
#' @export
sim_iw <- function(mat_scale, shape) {
    .Call(`_bvhar_sim_iw`, mat_scale, shape)
}

#' Generate Normal-IW Random Family
#' 
#' This function samples normal inverse-wishart matrices.
#' 
#' @param num_sim Number to generate
#' @param mat_mean Mean matrix of MN
#' @param mat_scale_u First scale matrix of MN
#' @param mat_scale Scale matrix of IW
#' @param shape Shape of IW
#' @details
#' Consider \eqn{(Y_i, \Sigma_i) \sim MIW(M, U, \Psi, \nu)}.
#' 
#' 1. Generate upper triangular factor of \eqn{\Sigma_i = C_i C_i^T} in the upper triangular Bartlett decomposition.
#' 2. Standard normal generation: s x m matrix \eqn{Z_i = [z_{ij} \sim N(0, 1)]} in row-wise direction.
#' 3. Lower triangular Cholesky decomposition: \eqn{U = P P^T}
#' 4. \eqn{A_i = M + P Z_i C_i^T}
#' 
#' @export
sim_mniw <- function(num_sim, mat_mean, mat_scale_u, mat_scale, shape) {
    .Call(`_bvhar_sim_mniw`, num_sim, mat_mean, mat_scale_u, mat_scale, shape)
}

#' VAR(1) Representation Given VAR Coefficient Matrix
#' 
#' Compute the VAR(1) coefficient matrix form
#' 
#' @param x VAR without constant coefficient matrix form
#' @details
#' Each VAR(p) process can be represented by mp-dim VAR(1).
#' 
#' \deqn{Y_t = A Y_{t - 1} + C + U_t}
#' 
#' where
#' 
#' \deqn{
#'     A = \begin{bmatrix}
#'       A_1 & A_2 & \cdots A_{p - 1} & A_p \\
#'       I_m & 0 & \cdots & 0 & 0 \\
#'       0 & I_m & \cdots & 0 & 0 \\
#'       \vdots & \vdots & \vdots & \vdots & \vdots \\
#'       0 & 0 & \cdots & I_m & 0
#'     \end{bmatrix}
#' }
#' 
#' \deqn{C = (c, 0, \ldots, 0)^T}
#' 
#' and
#' 
#' \deqn{U_t = (\epsilon_t^T, 0^T, \ldots, 0^T)^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
compute_stablemat <- function(x) {
    .Call(`_bvhar_compute_stablemat`, x)
}

#' VAR(1) Representation of VAR(p)
#' 
#' Compute the coefficient matrix of VAR(1) form
#' 
#' @param object Model fit
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
compute_var_stablemat <- function(object) {
    .Call(`_bvhar_compute_var_stablemat`, object)
}

#' VAR(1) Representation of VHAR
#'
#' Compute the coefficient matrix of VAR(1) form of VHAR
#'
#' @param object Model fit
#' @details
#' Note that \eqn{A^T = \Phi^T T_{HAR}}.
#' This gives the VAR(1) form of constrained VAR(22).
#'
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
compute_vhar_stablemat <- function(object) {
    .Call(`_bvhar_compute_vhar_stablemat`, object)
}

#' @noRd
kronecker_eigen <- function(x, y) {
    .Call(`_bvhar_kronecker_eigen`, x, y)
}

#' @noRd
vectorize_eigen <- function(x) {
    .Call(`_bvhar_vectorize_eigen`, x)
}

#' @noRd
compute_eigenvalues <- function(x) {
    .Call(`_bvhar_compute_eigenvalues`, x)
}

#' @noRd
compute_inverse <- function(x) {
    .Call(`_bvhar_compute_inverse`, x)
}

#' @noRd
compute_choleksy_lower <- function(x) {
    .Call(`_bvhar_compute_choleksy_lower`, x)
}

#' @noRd
compute_choleksy_upper <- function(x) {
    .Call(`_bvhar_compute_choleksy_upper`, x)
}

#' @noRd
qr_eigen <- function(x) {
    .Call(`_bvhar_qr_eigen`, x)
}

#' Multivariate Gamma Function
#' 
#' Compute multivariate gamma function numerically
#' 
#' @param x Double, non-negative argument
#' @param p Integer, dimension
#' 
#' @noRd
mgammafn <- function(x, p) {
    .Call(`_bvhar_mgammafn`, x, p)
}

#' Log of Multivariate Gamma Function
#' 
#' Compute log of multivariate gamma function numerically
#' 
#' @param x Double, non-negative argument
#' @param p Integer, dimension
#' 
#' @noRd
log_mgammafn <- function(x, p) {
    .Call(`_bvhar_log_mgammafn`, x, p)
}

#' Generate Multivariate Time Series Process Following VAR(p)
#' 
#' This function generates multivariate time series dataset that follows VAR(p).
#' 
#' @param num_sim Number to generated process
#' @param num_burn Number of burn-in
#' @param var_coef VAR coefficient. The format should be the same as the output of [coef.varlse()] from [var_lm()]
#' @param var_lag Lag of VAR
#' @param sig_error Variance matrix of the error term. Try `diag(dim)`.
#' @param init Initial y1, ..., yp matrix to simulate VAR model. Try `matrix(0L, nrow = var_lag, ncol = dim)`.
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
sim_var_eigen <- function(num_sim, num_burn, var_coef, var_lag, sig_error, init) {
    .Call(`_bvhar_sim_var_eigen`, num_sim, num_burn, var_coef, var_lag, sig_error, init)
}

#' Generate Multivariate Time Series Process Following VAR(p) using Cholesky Decomposition
#' 
#' This function generates VAR(p) using Cholesky Decomposition.
#' 
#' @param num_sim Number to generated process
#' @param num_burn Number of burn-in
#' @param var_coef VAR coefficient. The format should be the same as the output of [coef.varlse()] from [var_lm()]
#' @param var_lag Lag of VAR
#' @param sig_error Variance matrix of the error term. Try `diag(dim)`.
#' @param init Initial y1, ..., yp matrix to simulate VAR model. Try `matrix(0L, nrow = var_lag, ncol = dim)`.
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @noRd
sim_var_chol <- function(num_sim, num_burn, var_coef, var_lag, sig_error, init) {
    .Call(`_bvhar_sim_var_chol`, num_sim, num_burn, var_coef, var_lag, sig_error, init)
}

#' Generate Multivariate Time Series Process Following VHAR
#' 
#' This function generates multivariate time series dataset that follows VHAR.
#' 
#' @param num_sim Number to generated process
#' @param num_burn Number of burn-in
#' @param vhar_coef VHAR coefficient. The format should be the same as the output of [coef.vharlse()] from [vhar_lm()]
#' @param week Order for weekly term. Try `5L` by default.
#' @param month Order for monthly term. Try `22L` by default.
#' @param sig_error Variance matrix of the error term. Try `diag(dim)`.
#' @param init Initial y1, ..., y_month matrix to simulate VHAR model. Try `matrix(0L, nrow = month, ncol = dim)`.
#' @details
#' Let \eqn{M} be the month order, e.g. \eqn{M = 22}.
#' 
#' 1. Generate \eqn{\epsilon_1, \epsilon_n \sim N(0, \Sigma)}
#' 2. For i = 1, ... n,
#' \deqn{y_{M + i} = (y_{M + i - 1}^T, \ldots, y_i^T, 1)^T C_{HAR}^T \Phi + \epsilon_i}
#' 3. Then the output is \eqn{(y_{M + 1}, \ldots, y_{n + M})^T}
#' 
#' @references Lütkepohl, H. (2007). *New Introduction to Multiple Time Series Analysis*. Springer Publishing. doi:[10.1007/978-3-540-27752-1](https://doi.org/10.1007/978-3-540-27752-1)
#' @export
sim_vhar <- function(num_sim, num_burn, vhar_coef, week, month, sig_error, init) {
    .Call(`_bvhar_sim_vhar`, num_sim, num_burn, vhar_coef, week, month, sig_error, init)
}

#' Numerically Stable Log Marginal Likelihood Excluding Constant Term
#' 
#' This function computes log of ML stable,
#' in purpose of objective function.
#' 
#' @param object Bayesian Model Fit
#' 
#' @noRd
logml_stable <- function(object) {
    .Call(`_bvhar_logml_stable`, object)
}

#' AIC of VAR(p) using RSS
#' 
#' Compute AIC using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_aic <- function(object) {
    .Call(`_bvhar_compute_aic`, object)
}

#' BIC of VAR(p) using RSS
#' 
#' Compute BIC using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_bic <- function(object) {
    .Call(`_bvhar_compute_bic`, object)
}

#' HQ of VAR(p) using RSS
#' 
#' Compute HQ using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_hq <- function(object) {
    .Call(`_bvhar_compute_hq`, object)
}

#' FPE of VAR(p) using RSS
#' 
#' Compute FPE using RSS
#' 
#' @param object `varlse` or `vharlse` object
#' 
#' @noRd
compute_fpe <- function(object) {
    .Call(`_bvhar_compute_fpe`, object)
}

#' Choose the Best VAR based on Information Criteria
#' 
#' This function computes AIC, FPE, BIC, and HQ up to p = `lag_max` of VAR model.
#' 
#' @param y Time series data of which columns indicate the variables
#' @param lag_max Maximum Var lag to explore
#' @param include_mean Add constant term
#' 
#' @noRd
tune_var <- function(y, lag_max, include_mean) {
    .Call(`_bvhar_tune_var`, y, lag_max, include_mean)
}

